{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1B_-L4w5BYBu2CdnXZGT155hPjy4LGTkv",
      "authorship_tag": "ABX9TyNaEnUxX0Q+bJ0svtVynW4h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Redbaron13/setup-node/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "!pip3 install pandas numpy PyMuPDF fuzzywuzzy"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSHRRGo7DBas",
        "outputId": "614fde3a-e7e6-4b88-b348-ddefbc435e9b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.23.1)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.0 in /usr/local/lib/python3.11/dist-packages (from PyMuPDF) (1.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libxml2-dev libxslt1-dev antiword unrtf poppler-utils tesseract-ocr \\\n",
        "                     flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Reh6e2xlArHz",
        "outputId": "0f0e59a6-e064-4153-aa5b-dc95651ef1ec"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "antiword is already the newest version (0.37-16).\n",
            "lame is already the newest version (3.100-3build2).\n",
            "libmad0 is already the newest version (0.15.1b-10ubuntu1).\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "unrtf is already the newest version (0.21.10-clean-1).\n",
            "libxml2-dev is already the newest version (2.9.13+dfsg-1ubuntu0.6).\n",
            "libxslt1-dev is already the newest version (1.1.34-4ubuntu0.22.04.3).\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.7).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "flac is already the newest version (1.3.3-2ubuntu0.2).\n",
            "libsox-fmt-mp3 is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkZbmVWPCtSm",
        "outputId": "fb32eccb-0e08-436a-9cf4-5bc422513dd1"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas version: 2.2.2\n",
            "NumPy version: 2.0.2\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip3 install PyMuPDF==1.23.1 fuzzywuzzy==0.18.0"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8K8iw7clDwW",
        "outputId": "487473db-ea91-404a-c8bf-fff921a2f63b"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF==1.23.1 in /usr/local/lib/python3.11/dist-packages (1.23.1)\n",
            "Requirement already satisfied: fuzzywuzzy==0.18.0 in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: PyMuPDFb==1.23.0 in /usr/local/lib/python3.11/dist-packages (from PyMuPDF==1.23.1) (1.23.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# %%\n",
        "# --- Configuration for Local Runtime ---\n",
        "COMBOS_FOLDER = \"/content/drive/MyDrive/MakerhoodsFinDocs/Combo\"  # Update with your local path\n",
        "SPREADSHEET_PATH = \"/content/2makerhoods.xlsx\"  # Update with your local path\n",
        "DATABASE_NAME = \"account_data.db\"  # Keep this for the database\n",
        "\n",
        "# ... (Rest of the code remains the same) ...\n",
        "# %%\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/kmbfiles-a93d6849ab6a.json\""
      ],
      "cell_type": "code",
      "metadata": {
        "id": "RnnB1ODNB0aF"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import re\n",
        "from typing import List, Dict, Tuple\n",
        "import fitz  # PyMuPDF\n",
        "from fuzzywuzzy import fuzz\n",
        "import logging"
      ],
      "metadata": {
        "id": "Geqy4tK9dbvA"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming SPREADSHEET_PATH is correctly defined and contains the path to your spreadsheet\n",
        "SPREADSHEET_PATH = \"/2makerhoods.xlsx\"\n",
        "\n",
        "# Load the spreadsheet data into a pandas DataFrame called 'spreadsheet_data'\n",
        "spreadsheet_data = pd.read_excel(SPREADSHEET_PATH)\n",
        "\n",
        "# Now you can iterate through the rows:\n",
        "for index, row in spreadsheet_data.iterrows():\n",
        "    pass  # Add your logic to process each row here"
      ],
      "metadata": {
        "id": "0l9T5J07hwhV"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "source": [
        "def match_pdfs_to_accounts(pdf_files, spreadsheet_data):\n",
        "    \"\"\"Matches PDFs to accounts based on filename and spreadsheet data.\"\"\"\n",
        "    matched_pdfs = {}  # Store matched PDFs {account_index: [(pdf_index, matched_attributes)]}\n",
        "    potential_matches = {}  # Store potential matches {attribute: [pdf_indices]}\n",
        "\n",
        "    try:\n",
        "        for pdf_index, filename in pdf_files:\n",
        "            filename_lower = filename.lower()\n",
        "            for index, row in spreadsheet_data.iterrows(): # This block of code was not indented correctly\n",
        "                # Get relevant attributes from spreadsheet\n",
        "                account_name = str(row[\"AccountName\"]).lower()\n",
        "                bank_name = str(row[\"BankName\"]).lower()\n",
        "                account_type = str(row[\"AccountType\"]).lower()\n",
        "                account_group = str(row[\"AccountGroup\"]).lower()\n",
        "                account_number = str(row[\"AccountNumber\"]).lower()\n",
        "\n",
        "                matches = 0\n",
        "                matched_attributes = []  # Keep track of matched attributes\n",
        "\n",
        "                # Prioritize AccountNumber if available\n",
        "                if account_number and account_number in filename_lower:\n",
        "                    matches += 2  # Higher weight for AccountNumber match\n",
        "                    matched_attributes.append(\"AccountNumber\")\n",
        "\n",
        "                # Check for other attribute matches\n",
        "                for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                    if attribute and attribute in filename_lower:\n",
        "                        matches += 1\n",
        "                        matched_attributes.append(attribute.capitalize())\n",
        "\n",
        "                # Check for date-related keywords in filename (PDFFN1-6)\n",
        "                date_keywords = [\"q42024\", \"q12025\", \"october 2024\", \"november 2024\",\n",
        "                                \"march 2025\", \"april 2025\"]\n",
        "                if any(keyword in filename_lower for keyword in date_keywords):\n",
        "                    matches += 1  # Add weight for date-related keywords\n",
        "                    matched_attributes.append(\"DateKeyword\")  # Indicate date keyword match\n",
        "\n",
        "                # Assign matches based on priority and update spreadsheet\n",
        "                if matches > 1:  # At least 2 attributes or AccountNumber + DateKeyword match\n",
        "                    matched_pdfs.setdefault(index, []).append((pdf_index, matched_attributes))\n",
        "                    logging.debug(f\"PDF {filename} matched to account {index} based on: {', '.join(matched_attributes)}\")\n",
        "                elif matches == 1:  # Single attribute match (potential match)\n",
        "                    for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                        if attribute and attribute in filename_lower:\n",
        "                            potential_matches.setdefault(attribute, []).append(pdf_index)\n",
        "                            break\n",
        "\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Error: Spreadsheet is missing a required column: {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during PDF matching: {e}\")\n",
        "\n",
        "    return matched_pdfs, potential_matches"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "f4d0gikifSGR"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_and_categorize_pdfs(combos_folder):\n",
        "    \"\"\"Indexes and categorizes PDF files.\"\"\"\n",
        "    pdf_files = []\n",
        "    tax_docs = []\n",
        "\n",
        "    try:\n",
        "        for index, filename in enumerate(os.listdir(combos_folder)):\n",
        "            if filename.endswith(\".pdf\"):\n",
        "                pdf_index = str(index + 1).zfill(3)  # 3-digit index\n",
        "                if any(keyword in filename.lower() for keyword in [\"tax\", \"1099\", \"w-2\", \"w2\"]):\n",
        "                    tax_docs.append((pdf_index, filename))\n",
        "                else:\n",
        "                    pdf_files.append((pdf_index, filename))\n",
        "    except FileNotFoundError:\n",
        "        logging.error(f\"Error: The specified combos folder '{combos_folder}' was not found.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred while indexing PDFs: {e}\")\n",
        "\n",
        "    return pdf_files, tax_docs  # Return both lists"
      ],
      "metadata": {
        "id": "IGG7zH_ziIPm"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "source": [
        "def match_pdfs_to_accounts(pdf_files, spreadsheet_data):\n",
        "    \"\"\"Matches PDFs to accounts based on filename and spreadsheet data.\"\"\"\n",
        "    matched_pdfs = {}  # Store matched PDFs {account_index: [(pdf_index, matched_attributes)]}\n",
        "    potential_matches = {}  # Store potential matches {attribute: [pdf_indices]}\n",
        "\n",
        "    try:\n",
        "        for pdf_index, filename in pdf_files:\n",
        "            filename_lower = filename.lower()\n",
        "            for index, row in spreadsheet_data.iterrows():\n",
        "                # Get relevant attributes from spreadsheet\n",
        "                account_name = str(row[\"AccountName\"]).lower()\n",
        "                bank_name = str(row[\"BankName\"]).lower()\n",
        "                account_type = str(row[\"AccountType\"]).lower()\n",
        "                account_group = str(row[\"AccountGroup\"]).lower()\n",
        "                account_number = str(row[\"AccountNumber\"]).lower()\n",
        "\n",
        "                matches = 0\n",
        "                matched_attributes = []  # Keep track of matched attributes\n",
        "\n",
        "                # Prioritize AccountNumber if available\n",
        "                if account_number and account_number in filename_lower:\n",
        "                    matches += 2  # Higher weight for AccountNumber match\n",
        "                    matched_attributes.append(\"AccountNumber\")\n",
        "\n",
        "                # Check for other attribute matches\n",
        "                for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                    if attribute and attribute in filename_lower:\n",
        "                        matches += 1\n",
        "                        matched_attributes.append(attribute.capitalize())\n",
        "\n",
        "                # Check for date-related keywords in filename (PDFFN1-6)\n",
        "                date_keywords = [\"q42024\", \"q12025\", \"october 2024\", \"november 2024\",\n",
        "                                \"march 2025\", \"april 2025\"]\n",
        "                if any(keyword in filename_lower for keyword in date_keywords):\n",
        "                    matches += 1  # Add weight for date-related keywords\n",
        "                    matched_attributes.append(\"DateKeyword\")  # Indicate date keyword match\n",
        "\n",
        "                # Assign matches based on priority and update spreadsheet\n",
        "                if matches > 1:  # At least 2 attributes or AccountNumber + DateKeyword match\n",
        "                    matched_pdfs.setdefault(index, []).append((pdf_index, matched_attributes))\n",
        "                    logging.debug(f\"PDF {filename} matched to account {index} based on: {', '.join(matched_attributes)}\")\n",
        "                elif matches == 1:  # Single attribute match (potential match)\n",
        "                    for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                        if attribute and attribute in filename_lower:\n",
        "                            potential_matches.setdefault(attribute, []).append(pdf_index)\n",
        "                            break\n",
        "\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Error: Spreadsheet is missing a required column: {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during PDF matching: {e}\")\n",
        "\n",
        "    return matched_pdfs, potential_matches # Corrected indentation"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tYGDd_41jEWS"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_pdfs_to_accounts(pdf_files, spreadsheet_data):\n",
        "    \"\"\"Matches PDFs to accounts based on filename and spreadsheet data.\"\"\"\n",
        "    matched_pdfs = {}  # Store matched PDFs {account_index: [(pdf_index, matched_attributes)]}\n",
        "    potential_matches = {}  # Store potential matches {attribute: [pdf_indices]}\n",
        "\n",
        "    try:\n",
        "        for pdf_index, filename in pdf_files:\n",
        "            filename_lower = filename.lower()\n",
        "            for index, row in spreadsheet_data.iterrows():\n",
        "                # Get relevant attributes from spreadsheet\n",
        "                account_name = str(row[\"AccountName\"]).lower()\n",
        "                bank_name = str(row[\"BankName\"]).lower()\n",
        "                account_type = str(row[\"AccountType\"]).lower()\n",
        "                account_group = str(row[\"AccountGroup\"]).lower()\n",
        "                account_number = str(row[\"AccountNumber\"]).lower()\n",
        "\n",
        "                matches = 0\n",
        "                matched_attributes = []  # Keep track of matched attributes\n",
        "\n",
        "                # Prioritize AccountNumber if available\n",
        "                if account_number and account_number in filename_lower:\n",
        "                    matches += 2  # Higher weight for AccountNumber match\n",
        "                    matched_attributes.append(\"AccountNumber\")\n",
        "\n",
        "                # Check for other attribute matches\n",
        "                for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                    if attribute and attribute in filename_lower:\n",
        "                        matches += 1\n",
        "                        matched_attributes.append(attribute.capitalize())\n",
        "\n",
        "                # Check for date-related keywords in filename (PDFFN1-6)\n",
        "                date_keywords = [\"q42024\", \"q12025\", \"october 2024\", \"november 2024\",\n",
        "                                \"march 2025\", \"april 2025\"]\n",
        "                if any(keyword in filename_lower for keyword in date_keywords):\n",
        "                    matches += 1  # Add weight for date-related keywords\n",
        "                    matched_attributes.append(\"DateKeyword\")  # Indicate date keyword match\n",
        "\n",
        "                # Assign matches based on priority and update spreadsheet\n",
        "                if matches > 1:  # At least 2 attributes or AccountNumber + DateKeyword match\n",
        "                    matched_pdfs.setdefault(index, []).append((pdf_index, matched_attributes))\n",
        "                    logging.debug(f\"PDF {filename} matched to account {index} based on: {', '.join(matched_attributes)}\")\n",
        "                elif matches == 1:  # Single attribute match (potential match)\n",
        "                    for attribute in [account_name, bank_name, account_type, account_group]:\n",
        "                        if attribute and attribute in filename_lower:\n",
        "                            potential_matches.setdefault(attribute, []).append(pdf_index)\n",
        "                            break\n",
        "\n",
        "    except KeyError as e:\n",
        "        logging.error(f\"Error: Spreadsheet is missing a required column: {e}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during PDF matching: {e}\")\n",
        "\n",
        "    return matched_pdfs, potential_matches # Corrected indentation to align with the function definition"
      ],
      "metadata": {
        "id": "6lOcIIG6j3Mu"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After matching is done and spreadsheet_data is updated\n",
        "for index, row in spreadsheet_data.iterrows():\n",
        "    pdf_filenames = [row[f\"PDFFN{i}\"] for i in range(1, 7) if pd.notna(row[f\"PDFFN{i}\"])]\n",
        "    if len(pdf_filenames) != len(set(pdf_filenames)):  # Check for duplicates\n",
        "        spreadsheet_data.loc[index, \"PDFDup\"] = True\n",
        "    else:\n",
        "        spreadsheet_data.loc[index, \"PDFDup\"] = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEEWWvnvkfL8",
        "outputId": "452b7c27-b6e6-4c11-b7a0-4f1a21fac49f"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-122-13686923d525>:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  spreadsheet_data.loc[index, \"PDFDup\"] = False\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# %%\n",
        "def resolve_ambiguity(account_index, potential_matches, account_data):\n",
        "    \"\"\"Resolves ambiguity when multiple PDFs match an account based on filename.\"\"\"\n",
        "    logging.warning(f\"Multiple potential matches found for account index {account_index}:\")\n",
        "\n",
        "    # Limit the number of matches displayed\n",
        "    max_matches_to_display = 10\n",
        "    displayed_matches = potential_matches[:max_matches_to_display]\n",
        "\n",
        "    for i, match in enumerate(displayed_matches):\n",
        "        pdf_index, filename = match\n",
        "        logging.warning(f\"{i+1}. PDF Index: {pdf_index}, Filename: {filename}\")\n",
        "\n",
        "    if len(potential_matches) > max_matches_to_display:\n",
        "        logging.warning(f\"   ...and {len(potential_matches) - max_matches_to_display} more potential matches.\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"Enter the number of the correct PDF, 'n' for none, 's' to skip: \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(displayed_matches):\n",
        "            return displayed_matches[int(choice)-1][0]\n",
        "        elif choice.lower() == 'n':\n",
        "            return None\n",
        "        elif choice.lower() == 's':\n",
        "            return 'skip'\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "# %%\n",
        "def sort_matched_pdfs(matched_pdfs):\n",
        "       \"\"\"Sorts matched PDFs by date extracted from filename.\"\"\"\n",
        "       for account_index, pdf_data in matched_pdfs.items():\n",
        "           # Sort by date, handling None values (no date found)\n",
        "           matched_pdfs[account_index] = sorted(pdf_data, key=lambda x: extract_date_from_filename(x[0]) or \"\", reverse=True)\n",
        "# %%\n",
        "def assign_pdf_filenames_to_spreadsheet(matched_pdfs, spreadsheet_data):\n",
        "       \"\"\"Assigns sorted PDF filenames to PDFFN1-6 columns in spreadsheet.\"\"\"\n",
        "       for account_index, pdf_data in matched_pdfs.items():\n",
        "           for i, (pdf_index, _) in enumerate(pdf_data):  # _ ignores matched_attributes\n",
        "               column_name = f\"PDFFN{i + 1}\"\n",
        "               if column_name in spreadsheet_data.columns and i < 6:  # Assign to max 6 columns\n",
        "                   spreadsheet_data.loc[account_index, column_name] = pdf_index\n",
        "# %%"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "BiCufSrAfngZ"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_date_from_filename(filename):\n",
        "    \"\"\"Extracts date from filename using regex.\"\"\"\n",
        "    date_patterns = [\n",
        "        r\"(\\d{2}-\\d{2}-\\d{4})\",  # MM-DD-YYYY\n",
        "        r\"(\\d{4}-\\d{2}-\\d{2})\",  # YYYY-MM-DD\n",
        "        r\"(\\w{3} \\d{2}, \\d{4})\",  # Month DD, YYYY\n",
        "        r\"(\\d{4})\"  # Year only\n",
        "    ]\n",
        "    for pattern in date_patterns:\n",
        "        match = re.search(pattern, filename, re.IGNORECASE)\n",
        "        if match:\n",
        "            return match.group(1)\n",
        "    return None  # Return None if no date found"
      ],
      "metadata": {
        "id": "38bO1E6Nkt7n"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvg5yV1SlhE_"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "source": [
        "def main():\n",
        "    try:\n",
        "        # Your code to index, match, sort, etc. goes here\n",
        "        # Example:\n",
        "        pdf_files, tax_docs = index_and_categorize_pdfs(COMBOS_FOLDER)\n",
        "        # ... more of your code ...\n",
        "    except Exception as e:\n",
        "        logging.error(f\"A critical error occurred during program execution: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "C4QYNb6NijW9"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_NefmUKZlWkD"
      }
    },
    {
      "source": [
        "def main():\n",
        "    try:\n",
        "        # ... (Your existing code for indexing, matching, sorting, etc.) ...\n",
        "        # This line and any other code within the try block should be indented\n",
        "        # For example:\n",
        "        # pdf_files, tax_docs = index_and_categorize_pdfs(COMBOS_FOLDER)\n",
        "        # matched_pdfs, potential_matches = match_pdfs_to_accounts(pdf_files, spreadsheet_data)\n",
        "        pass  # Replace pass with your actual code\n",
        "    except Exception as e:\n",
        "        logging.error(f\"A critical error occurred during program execution: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oIvs3r-IlUrH"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "source": [
        "def main():\n",
        "    # ... (Your existing code) ...\n",
        "\n",
        "    # ... (Matching and potential matching logic) ...\n",
        "\n",
        "    # Sort matched PDFs by date\n",
        "    sort_matched_pdfs(matched_pdfs)\n",
        "\n",
        "    # Assign PDF filenames to spreadsheet\n",
        "    assign_pdf_filenames_to_spreadsheet(matched_pdfs, spreadsheet_data)\n",
        "\n",
        "    # ... (Rest of your code, including saving the updated spreadsheet) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "t2dH445Fi1ip"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "source": [
        "def main():\n",
        "    # ... (Your existing code) ...\n",
        "    pdf_files, tax_docs = index_and_categorize_pdfs(COMBOS_FOLDER)\n",
        "    # Get matched_pdfs and potential_matches\n",
        "    matched_pdfs, potential_matches = match_pdfs_to_accounts(pdf_files, spreadsheet_data)\n",
        "\n",
        "    # Sort matched PDFs by date\n",
        "    sort_matched_pdfs(matched_pdfs)\n",
        "\n",
        "    # Assign PDF filenames to spreadsheet\n",
        "    assign_pdf_filenames_to_spreadsheet(matched_pdfs, spreadsheet_data)\n",
        "\n",
        "    # ... (Rest of your code, including saving the updated spreadsheet) ...\n",
        "    # ... (After assigning PDF filenames) ...\n",
        "    for attribute, pdf_indices in potential_matches.items():\n",
        "        try:\n",
        "            # 1. Extract text from PDFs\n",
        "            # ... (Your logic for text extraction) ...\n",
        "\n",
        "            # 2. Identify account numbers using regex\n",
        "            # ... (Your logic for account number identification) ...\n",
        "\n",
        "            # 3. Compare and resolve ambiguities\n",
        "            # ... (Your logic for comparison and ambiguity resolution) ...\n",
        "            pass  # Add a placeholder statement if you don't have any logic yet\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing potential matches for attribute '{attribute}': {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0XspGr6ZiEMv"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "source": [
        "spreadsheet_data = pd.read_excel(SPREADSHEET_PATH)  # Load your spreadsheet\n",
        "# ... (Your existing code for indexing, categorizing, matching, sorting, and assigning PDF filenames) ...\n",
        "spreadsheet_data.to_excel(\"updated_spreadsheet.xlsx\", index=False)  # Save the updated spreadsheet"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "g8l-OfDegDvD"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "source": [
        "# ... (Your existing code) ...\n",
        "def main():\n",
        "    # ... (Your existing code) ...\n",
        "    pdf_files, tax_docs = index_and_categorize_pdfs(COMBOS_FOLDER)\n",
        "    # Get matched_pdfs and potential_matches\n",
        "    matched_pdfs, potential_matches = match_pdfs_to_accounts(pdf_files, spreadsheet_data)\n",
        "\n",
        "    # ... (Your existing code for sorting and assigning filenames) ...\n",
        "\n",
        "    # Now process potential matches:\n",
        "    for attribute, pdf_indices in potential_matches.items():\n",
        "        # Implement logic to analyze PDFs in potential_matches:\n",
        "        # 1. Extract text from PDFs\n",
        "        # 2. Identify account numbers using regex or other techniques\n",
        "        # ... (rest of your logic)\n",
        "        print(attribute, pdf_indices)  # Added this line for debugging - remove later\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()  # Call the main function to execute the code"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zmmxC5NgEx4",
        "outputId": "6478c2b4-c264-412a-cbf5-920373ea7eb4"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error: Spreadsheet is missing a required column: 'BankName'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (After handling potential matches) ...\n",
        "for account_index, row in spreadsheet_data.iterrows():\n",
        "    for pdf_filename in row[['PDFFN1', 'PDFFN2', 'PDFFN3', 'PDFFN4', 'PDFFN5', 'PDFFN6']].values:\n",
        "        if pd.notna(pdf_filename):\n",
        "            # Construct the full file path\n",
        "            full_pdf_path = os.path.join(COMBOS_FOLDER, pdf_filename)\n",
        "            try:\n",
        "                # 1. Open the PDF file using the full path\n",
        "                pdf_document = fitz.open(full_pdf_path)\n",
        "\n",
        "                # 2. Extract data (example - get text from the first page)\n",
        "                page_text = pdf_document[0].get_text()\n",
        "\n",
        "                # 3. Populate spreadsheet (example - write text to a column)\n",
        "                spreadsheet_data.loc[account_index, \"ExtractedText\"] = page_text\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error extracting data from PDF '{pdf_filename}' for account {account_index}: {e}\")"
      ],
      "metadata": {
        "id": "088MjBKTuzH-"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "source": [
        "try:\n",
        "    # 1. Open the PDF file\n",
        "    # ... (Your logic for opening the PDF) ...\n",
        "\n",
        "    # 2. Extract data\n",
        "    # ... (Your logic for data extraction) ...\n",
        "\n",
        "    # 3. Populate spreadsheet\n",
        "    # ... (Your logic for populating the spreadsheet) ...\n",
        "except Exception as e:  # Indentation corrected\n",
        "    logging.error(f\"Error extracting data from PDF '{pdf_filename}' for account {account_index}: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "tpvrVaAdocP5",
        "outputId": "e0e78994-01b6-4e7d-9bcd-913d9e40de08"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after 'try' statement on line 1 (<ipython-input-134-35a255a80b74>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-134-35a255a80b74>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    except Exception as e:  # Indentation corrected\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'try' statement on line 1\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# ... (After handling potential matches) ...\n",
        "for account_index, row in spreadsheet_data.iterrows():\n",
        "    for pdf_filename in row[['PDFFN1', 'PDFFN2', 'PDFFN3', 'PDFFN4', 'PDFFN5', 'PDFFN6']].values:\n",
        "        if pd.notna(pdf_filename):\n",
        "            # Construct the full file path\n",
        "            full_pdf_path = os.path.join(COMBOS_FOLDER, pdf_filename)\n",
        "            try:\n",
        "                # 1. Open the PDF file using the full path\n",
        "                pdf_document = fitz.open(full_pdf_path)\n",
        "\n",
        "                # 2. Extract data (example - get text from the first page)\n",
        "                page_text = pdf_document[0].get_text()\n",
        "\n",
        "                # 3. Populate spreadsheet (example - write text to a column)\n",
        "                spreadsheet_data.loc[account_index, \"ExtractedText\"] = page_text\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error extracting data from PDF '{pdf_filename}' for account {account_index}: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iFl6Wj0NuwsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# ... (After handling potential matches) ...\n",
        "for account_index, row in spreadsheet_data.iterrows():\n",
        "    for pdf_filename in row[['PDFFN1', 'PDFFN2', 'PDFFN3', 'PDFFN4', 'PDFFN5', 'PDFFN6']].values:\n",
        "        if pd.notna(pdf_filename):\n",
        "            try:\n",
        "                # 1. Open the PDF file (example using PyMuPDF)\n",
        "                pdf_document = fitz.open(pdf_filename)\n",
        "\n",
        "                # 2. Extract data (example - get text from the first page)\n",
        "                page_text = pdf_document[0].get_text()\n",
        "\n",
        "                # 3. Populate spreadsheet (example - write text to a column)\n",
        "                spreadsheet_data.loc[account_index, \"ExtractedText\"] = page_text\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error extracting data from PDF '{pdf_filename}' for account {account_index}: {e}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "LA9wkUOmiKeP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}